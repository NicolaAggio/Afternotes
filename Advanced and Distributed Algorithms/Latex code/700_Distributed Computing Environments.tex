\section{Distributed Computing Environments}
The following chapters focus on the algorithmics of distributed computing; that is, on how to solve problems and perform tasks efficiently in a distributed computing environment. 

This universe consists of a finite collection of computational entities communicating by means of messages in order to achieve a common goal; for example, to perform a given task, to compute the solution to a problem, to satisfy a request either from the user (i.e., outside the environment) or from other entities. Although each entity is capable of performing computations, it is the collection of all these entities that together will solve the problem or ensure that the task is performed. 

In this universe, to solve a problem, we must discover and design a distributed algorithm or protocol for those entities: A set of rules that specify what each entity has to do. The collective but autonomous execution of those rules, possibly without any supervision or synchronization, must enable the entities to perform the desired task to solve the problem. In the design process, we must ensure both \textbf{correctness} (i.e., the protocol we design indeed solves the problem) and \textbf{efficiency} (i.e., the protocol we design has a “small” cost).

\subsection{Entities}
The computational unit of a distributed computing environment is called an entity. Depending on the system being modeled by the environment, an entity could correspond to a process, a processor, a switch, an agent, and so forth in the system.

\paragraph{Capabilities} Each entity $x \in \mathcal{E}$ is endowed with \textbf{local} (i.e., private and non-shared) \textbf{memory} $M_x$. The capabilities of $x$ include:
\begin{itemize}
    \item \textbf{Access} (storage and retrieval) to local memory;
    \item \textbf{Local processing};
    \item \textbf{Communication} (preparation, transmission, and reception of messages).
\end{itemize}

Local memory includes a set of defined \textbf{registers} whose values are always initially defined, e.g. the \textbf{status} register (denoted by \textit{status(x)}), which takes values from a finite set of system states $S$; the examples of such values are “Idle”, “Processing,” “Waiting”, and so forth. Another example of register is the \textbf{input value} register, denoted by \textit{value(x)}.

In addition, each entity $x \in \mathcal{E}$ has available a local alarm \textbf{clock} $c_x$ which it can set and reset (turn off). 

An entity can perform only four types of \textbf{operations}:
\begin{itemize}
    \item \textbf{Local storage} and \textbf{processing};
    \item \textbf{Transmission} of messages;
    \item Setting of the \textbf{alarm clock};
    \item \textbf{Changing} the \textbf{value} of the status register.
\end{itemize}

\paragraph{External Events} The \textbf{behavior} of an entity $x \in \mathcal{E}$ is \textbf{reactive}: $x$ only responds to external stimuli, which we call external events (or just events); in the absence of stimuli, $x$ is inert and does nothing. 

There are three possible external events:
\begin{itemize}
    \item \textbf{Arrival} of a message;
    \item \textbf{Ringing} of the alarm clock;
    \item \textbf{Spontaneous} impulse.
\end{itemize}

The arrival of a message and the ringing of the alarm clock are the events that are \textbf{external} to the entity but originate within the system: the message is sent by another entity, and the alarm clock is set by the entity itself. 

Unlike the other two types of events, a spontaneous impulse is triggered by forces external to the system and thus \textbf{outside} the universe perceived by the entity. As an example of event generated by forces external to the system, consider an automated banking system: its entities are the bank servers where the data is stored, and the automated teller machine (ATM) machines; the request by a customer for a cash withdrawal (i.e., update of data stored in the system) is a spontaneous impulse for the ATM machine (the entity) where the request is made. 

\paragraph{Actions} When an external event $e$ occurs, an entity $x \in \mathcal{E}$ will react to $e$ by performing a finite, indivisible, and terminating sequence of operations called \textbf{action}.

An action is indivisible (or \textbf{atomic}) in the sense that its operations are executed without interruption; in other words, once an action starts, it will not stop until it is finished. An action is terminating in the sense that, once it is started, its execution ends within finite time. 

A special action that an entity may take is the \textbf{null action}, where the entity does not react to the event.

\paragraph{Behaviour} The nature of the action performed by the entity depends on the nature of the event $e$, as well as on which status the entity is in (i.e., the value of \textit{status(x)}) when the events occur. 

Thus the specification will take the form
$$ Status \times Event \xrightarrow{} Action$$
which will be called a \textbf{rule}.

The \textbf{behavior} of an entity $x$ is the set $B(x)$ of all the rules that $x$ obeys. This set must be \textbf{complete} and \textbf{non-ambiguous}: for every possible event $e$ and status value $s$, there is one and only one rule in $B(x)$ enabled by $(s,e)$. In other words, $x$ must always know exactly what it must do when an event occurs. 

The \textbf{behavioral specification} of the entire \textbf{distributed computing environment} is just the collection of the individual behaviors of the entities. More precisely, the \textbf{collective behavior} $\behav$ of a collection $\mathcal{E}$ of entities is the set
$$\behav ={B(x): x \in \mathcal{E}}$$
Thus, in an environment with collective behavior $\behav$, each entity $x$ will be acting (behaving) according to its distributed algorithm and protocol (set of rules) $B(x)$.

\paragraph{Homogeneous Behavior} A collective behavior is \textbf{homogeneous} if all entities in the system have the same behavior, that is, $\forall x, y \in \mathcal{E}, B(x) = B(y)$. 

This means that to specify a homogeneous collective behavior, it is sufficient to specify the behavior of a single entity; in this case, we will indicate the behavior simply by $B$. An interesting and important fact is the following: \textbf{every collective behavior can be made homogeneous}. This means that if we are in a system where different entities have different behaviors, we can write a new set of rules, the same for all of them, which will still make them behave as before.

\example{Consider a system composed of a network of several identical workstations and a single server; clearly, the set of rules that the server and a workstation obey is not the same as their functionality differs. Still, a single program can be written that will run on both entities without modifying their functionality. We need to add to each entity an input register, $my\_role$, which is initialized to either “workstation” or “server,” depending on the entity; for each status–event pair $(s, e)$ we create a new rule with the following action: $$s \times e \xrightarrow{} \{\text{if } my\_role = \text{workstation then } A_{workstation} \text{ else } A_{server}\}$$ where $A_{workstation}$ (respectively, $A_{server}$) is the original action associated to $(s, e)$ in the set of rules of the workstation (respectively, server). If $(s, e)$ did not enable any rule for a workstation (e.g., $s$ was a status defined only for the server), then $A_{workstation} = \text{NIL}$ in the new rule; analogously for the server.}

It is important to stress that in a \textbf{homogeneous system}, although all entities have the \textbf{same behavioral description} (software), they \textbf{do not have to act in the same way}; their difference will depend solely on the initial value of their input registers. An important consequence of the homogeneous behavior property is that we can concentrate solely on environments where all the entities have the same behavior. From now on, when we mention behavior we will always mean homogeneous collective behavior.

\subsection{Communication}
In a distributed computing environment, entities communicate by transmitting and receiving messages. The message is the unit of \textbf{communication} of a distributed environment.  

An entity communicates by \textbf{transmitting messages} to and \textbf{receiving messages} from other entities. The \textbf{set of entities} with which an entity can communicate directly is not necessarily $\mathcal{E}$; in other words, it is possible that an entity can communicate directly only with a subset of the other entities. We denote by $N_{out}(x) \subseteq \mathcal{E}$ the set of entities to which $x$ can transmit a message directly; we shall call them the \textbf{out-neighbors} of $x$. Similarly, we denote by $N_{in}(x) \subseteq \mathcal{E}$ the set of entities from which $x$ can receive a message directly; we shall call them the \textbf{in-neighbors} of $x$. 

The \textbf{neighborhood} relationship defines a directed graph $G = (V,E)$ where $V$ is the set of vertices and $E \subseteq V \times V$ is the set of edges; the vertices correspond to entities, and $(x, y) \in 
E$ if and only if the entity (corresponding to) $y$ is an out-neighbor of the entity (corresponding to) $x$. 

In summary, an \textbf{entity} can only \textbf{receive} messages from its \textbf{in-neighbors} and \textbf{send} messages to its \textbf{out-neighbors}. Messages received at an entity are processed there in the order they arrive; if more than one message arrive at the same time, they will be processed in arbitrary order. Entities and communication may fail.

\subsection{Axioms and restrictions}
The definition of distributed computing environment with point-to-point communication has two basic axioms, one on communication delay, and the other on the local orientation of the entities in the system.

\subsubsection{Axioms}
\paragraph{Communication Delays} Communication of a message involves many activities: preparation, transmission, reception, and processing. In real systems described by our model, the \textbf{time} required by these activities is \textbf{unpredictable}. For example, in a communication network a message will be subject to queueing and processing delays, which change depending on the network traffic at that time; for example, consider the delay in accessing (i.e., sending a message to and getting a reply from) a popular web site. 

The totality of delays encountered by a message will be called the \textbf{communication delay} of that message. The axiom states that, in the \textbf{absence of failures}, \textbf{communication delays are finite}. In other words, in the absence of failures, a message sent to an out-neighbor will eventually arrive in its integrity and be processed there. 

Note that the Finite Communication Delays axiom does not imply the existence of any bound on transmission, queueing, or processing delays; it only states that in the absence of failure, a message will arrive after a finite amount of time without corruption.

\paragraph{Local Orientation}
An entity can communicate directly with a subset of the other entities: its neighbors. The only other axiom in the model is that an \textbf{entity can distinguish between its neighbors}, in particular it can distinguish among its in-neighbors and among its out-neighbors.

An entity is capable of sending a message only to a specific out-neighbor (without having to send it also to all other out-neighbors). Also, when processing a message (i.e., executing the rule enabled by the reception of that message), an entity can distinguish which of its in-neighbors sent that message. 

In other words, each entity $x$ has a local function $\lambda_x$ associating labels, also called \textbf{port numbers}, to its incident links (or \textbf{ports}), and this function is injective. We denote port numbers by $\lambda_x(x,y)$, the label associated by $x$ to the link $(x, y)$. Let us stress that this label is local to $x$ and in general has no relationship at all with what $y$ might call this link (or $x$, or itself). Note that for each edge $(x, y) \in \mathcal{E}$, there are two labels: $\lambda_x(x, y)$ local to $x$ and $\lambda_y(x, y)$ local to $y$. 

\image{dc1.png}{1.5}{Every edge has two labels.}

Because of this axiom, we will always deal with edge-labeled graphs $( G, \lambda)$, where $\lambda ={\lambda_x : x \in V}$ is the set of these injective labelings.

\subsubsection{Restrictions}
In general, a distributed computing system might have additional \textbf{properties} or capabilities that can be exploited to solve a problem, to achieve a task, and to provide a service. This can be achieved by using these properties and capabilities in the set of rules. 

However, any property used in the protocol limits the applicability of the protocol. In other words, any additional property or capability of the system is actually a \textbf{restriction} (or submodel) of the general model.

The restrictions can be varied in nature and type: they might be related to communication properties, reliability, synchrony, and so forth. In the following section, we will discuss some of the most common restrictions.

\paragraph{Communication Restrictions} 
The first category of restrictions includes those relating to \textbf{communication} among \textbf{entities}.

\textit{Queueing policy} A \textbf{link} $(x, y)$ can be viewed as a \textbf{channel} or a \textbf{queue}: $x$ sending a message to $y$ is equivalent to $x$ inserting the message in the channel. In general, all kinds of situations are possible; for example, messages in the channel might overtake each other, and a later message might be received first. Different restrictions on the model will describe different disciplines employed to manage the channel; for example, first-in-first-out (\textbf{FIFO}) queues are characterized by the following restriction.

\begin{itemize}
    \item \textbf{Message Ordering}: In the \textbf{absence of failure}, the \textbf{messages} transmitted by an entity to the same out-neighbor will arrive in the \textbf{same order} they are \textbf{sent}.
\end{itemize}

Note that Message Ordering \textbf{does not imply} the \textbf{existence} of any \textbf{ordering} for messages transmitted to the same entity \textbf{from different edges}, nor for messages sent by the same entity on different edges.

\textit{Link property} Entities in a communication system are connected by \textbf{physical links}, which may be very different in capabilities. The examples are \textbf{simplex} and \textbf{full-duplex} links. With a fully duplex line it is possible to transmit in both directions. Simplex lines are already defined within the general model. A duplex line can obviously be described as two simplex lines, one in each direction; thus, a system where all lines are fully duplex can be described by the following restriction:

\begin{itemize}
    \item \textbf{Reciprocal communication}: $\forall x \in \mathcal{E}, N_{in}(x) = N_{out}(x)$. In other words, if $(x, y) \in E$ then also $(y, x) \in E$.
\end{itemize}

Notice that, however, $(x, y) \neq (y, x)$, and in general $\lambda_x(x, y) \neq \lambda_x(y, x)$; furthermore, $x$ might not know that these two links are connections to and from the same entity. A system with fully duplex links that offers such a knowledge is defined by the following restriction.
\begin{itemize}
    \item \textbf{Bidirectional links}: $\forall x \in \mathcal{E}, N_{in}(x) = N_{out}(x)$ and $\lambda_x(x, y) = \lambda_x(y, x)$.
\end{itemize}

\image{dc2.png}{1.5}{In a network with bidirectional links we consider the corresponding undirected graph.}

\paragraph{Reliability restrictions}
Other types of restrictions are those related to reliability, faults, and their detection.

\textit{Detection of Faults} Some systems might provide a reliable fault-detection mechanism. Following are two restrictions that describe systems that offer such capabilities in regard to component failures:
\begin{itemize}
    \item \textbf{Edge failure detection}: $\forall (x, y) \in  E$, both $x$ and $y$ will detect whether $(x, y)$ has failed and, following its failure, whether it has been reactivated;
    \item \textbf{Entity failure detection}: $\forall x \in V$, all in- and out-neighbors of $x$ can detect whether $x$ has failed and, following its failure, whether it has recovered.
\end{itemize}

\textit{Restricted Types of Faults} In some systems only some types of failures can occur: for example, messages can be lost but not corrupted. Each situation will give rise to a corresponding restriction. More general restrictions will describe systems or situations where there will be no failures:
\begin{itemize}
    \item \textbf{Guaranteed delivery}: \textbf{Any message} that is sent will be \textbf{received} with its content \textbf{uncorrupted}. Under this restriction, protocols do not need to take into account omissions or corruptions of messages during transmission. Even more general is the following;
    \item \textbf{Partial reliability}: \textbf{No failures will occur}. Under this restriction, protocols do not need to take failures into account. Note that under Partial Reliability, failures might have occurred before the execution of a computation. A totally fault-free system is defined by the following restriction;
    \item \textbf{Total reliability}: Neither have \textbf{any failures occurred} nor \textbf{will they occur}. 
\end{itemize}
Clearly, protocols developed under this restriction are not guaranteed to work correctly if faults occur.

\paragraph{Topological Restrictions} In general, an entity is not directly connected to all other entities; it might still be able to communicate information to a remote entity, using others as relayer. A system that provides this capability for all entities is characterized by the following restriction:
\begin{itemize}
    \item \textbf{Connectivity}: The communication topology $G$ is \textbf{strongly connected}.
\end{itemize} 

That is, from every vertex in $G$ it is possible to reach every other vertex. In case the restriction “Bidirectional Links” holds as well, connectedness will simply state that $G$ is \textbf{connected}.

\paragraph{Time Restrictions} An interesting type of restrictions is the one relating to time. In fact, the general model makes no assumption about delays (except that they are finite).
\begin{itemize}
    \item \textbf{Bounded communication delays}: There exists a constant $\Delta$ such that, in the absence of failures, the communication delay of any message on any link is at most $\Delta$.
\end{itemize}

A special case of bounded delays is the following:
\begin{itemize}
    \item \textbf{Unitary communication delays}: In the absence of failures, the communication delay of any message on any link is one unit of time. The general model also makes no assumptions about the local clocks;
    \item \textbf{Synchronized clocks}: All local clocks are incremented by one unit simultaneously and the interval of time between successive increments is constant.
\end{itemize}

Usually, we'll consider asynchronous systems.

\subsection{Cost and complexity}
We will use two types of measures: the \textbf{amount of communication activities} and the \textbf{time} required by the execution of a computation. They can be seen as measuring costs from the system point of view (\textit{How much traffic will this computation generate and how busy will the system be?}) and from the user point of view (\textit{How long will it take before I get the results of the computation?})

\subsubsection{Amount of communication activities}
The transmission of a message through an out-port (i.e., to an out-neighbor) is the basic communication activity in the system; note that the transmission of a message that will not be received because of failure still constitutes a communication activity. Thus, to measure the amount of communication activities, the most common function used is the number of message transmissions $M$, also called \textbf{message cost}. So in general, given a protocol, we will measure its communication costs in terms of the \textbf{number of transmitted messages}.

\subsubsection{Time}
An important measure of efficiency and complexity is the \textbf{total execution delay}, that is, the delay between the time the first entity starts the execution of a computation and the time the last entity terminates its execution.

In the general model there is \textbf{no assumption} about time except that communication delays for a single message are finite in absence of failure. In other words, \textbf{communication delays} are in general \textbf{unpredictable}. Thus, even in the absence of failures, the total execution delay for a computation is totally unpredictable; furthermore, two distinct executions of the same protocol might experience drastically different delays. In other words, we cannot accurately measure time. 

We, however, can measure time assuming particular conditions. The measure usually employed is the \textbf{ideal execution delay} or ideal time complexity, $T$: the execution delay experienced under the restrictions “Unitary Transmission Delays” and “Synchronized Clocks;” that is, when the system is synchronous and (in the absence of failure) takes one unit of time for a message to arrive and to be processed. 

A very different cost measure is the \textbf{causal time complexity}, $T_{causal}$. It is defined as the length of the longest chain of causally related message transmissions, over all possible executions. Causal time is seldom used and is very difficult to measure exactly; we will employ it only once, when dealing with synchronous computations.

\subsection{Broadcasting}
Let us clarify the concepts expressed so far by means of an example. Consider a distributed computing system where one entity has some important information unknown to the others and would like to share it with everybody else.  This problem is called \textbf{broadcasting}.

Let $\mathcal{E}$ be the \textbf{collection of entities} and $G$ be the \textbf{communication topology}. To simplify the discussion, we will make some additional \textbf{assumptions} (i.e., restrictions) on the system:
\begin{enumerate}
    \item \textbf{Bidirectional links}; that is, we consider the undirected graph $G$;
    \item \textbf{Total reliability}, that is, we do not have to worry about failures. Observe that, if $G$ is disconnected, some entities can never receive the information, and the broadcasting problem will be unsolvable. Thus, a restriction that (unlike the previous two) we need to make is as follows.
    \item \textbf{Connectivity}; that is, $G$ is connected. Further observe that built in the definition of the problem, there is the assumption that only the entity with the initial information will start the broadcast. Thus, a restriction built in the definition is as follows.
    \item \textbf{Unique Initiator}, that is, only one entity will start.
\end{enumerate}

\subsubsection{Flooding algorithm}
A simple strategy for solving the broadcast problem is the following: \textit{“if an entity knows the information, it will share it with its neighbors.”}

To construct the set of rules implementing this strategy, we need to define the set $S$ of \textbf{status values}; from the statement of the problem it is clear that we need to distinguish between the entity that initially has the information and the others: $\{\text{initiator}, \text{sleeping}\} \subseteq S$. The process can be started only by the initiator, while the other entities are sleeping; let $I$ denote the information to be broadcasted. 

Here is the \textbf{set of rules} $B(x)$ (the same for all entities).

\image{dc3.png}{1.5}{Set of rules of the Flood algorithm}

Because of \textbf{connectivity} and \textbf{total reliability}, every entity will eventually receive the information. Hence, the protocol achieves its goal and \textbf{solves the broadcasting problem}. 

However, there is a serious problem with these rules: the \textbf{activities} generated by the protocol \textbf{never terminate}.

Consider, for example, the simple system with three entities $x, y, z$ connected to each other. Let $x$ be the initiator, $y$ and $z$ be idle, and all messages travel at the same speed; then $y$ and $z$ will be forever sending messages to each other (as well as to $x$).

\image{dc4.png}{1.5}{Execution of the Flood algorithm.}

To avoid this unwelcome effect, an \textbf{entity} should \textbf{send} the \textbf{information} to its neighbors \textbf{only once}: the first time it acquires the information. This can be achieved by introducing a new status done; that is $S =\{\text{initiator}, \text{sleeping}, \text{done}\}$.

\image{dc5.png}{1.5}{Set of rules of the Flood algorithm.}

This time the communication activities of the protocol \textbf{terminate}: Within finite time all entities become done; since a done entity knows the information, the \textbf{protocol} is \textbf{correct}. Note that depending on transmission delays, different executions are possible; one such execution in an environment composed of three entities $x, y, z$ connected to each other.

Notice that in this case:
\begin{itemize}
    \item The \textbf{states} are INITIATOR, SLEEPING and DONE;
    \item The \textbf{events} are SPONTANEOUSLY and RECEIVING(I);
    \item The \textbf{actions} are $send(I)$, etc..
\end{itemize}

\imageTriple{dc6.png}{dc7.png}{dc8.png}{1.2}{1.2}{1.2}{Example of execution of the Flood algorithm.}

Note that \textbf{entities} \textbf{terminate} their execution of the protocol (i.e., become done) at \textbf{different times}; it is actually possible that an entity has terminated while others have not yet started. This is something very typical of distributed computations: There is a difference between local termination and global termination.

Notice also that in this protocol \textbf{nobody} ever \textbf{knows} when the \textbf{entire process is over}. We will examine these issues in details in other chapters, in particular when discussing the problem of termination detection.

Now, our next goal is to prove the \textbf{correctness} of the algorithm, in particular:
\begin{enumerate}
    \item The algorithm \textbf{correctly solves the problem}: if $G$ is connected and there is total reliability, every entity will eventually receive the information;
    \item The algorithm \textbf{terminates}: if an entity has received the message it will enter the state done and it will terminate.
\end{enumerate}

First of all, let us determine the \textbf{number of message transmissions}. Each entity, whether initiator or not, sends the information to all its neighbors. Hence the total number of messages transmitted is exactly:

$$\mess[\text{Flooding}] = \sum_{x \in \mathcal{E}} |N(x)|= 2 |E|= 2 m$$

We can actually \textbf{reduce the cost}. Currently, when an idle entity receives the message, it will broadcast the information to all its neighbors, including the entity from which it had received the information; this is clearly \textbf{unnecessary}. Recall that, by the Local Orientation axiom, an entity can distinguish among its neighbors; in particular, when processing a message, it can identify from which port it was received and avoid sending a message there. In this case the number of messages will be:

$$
\mess[\text{Flooding}] = \sum_{x \in \mathcal{E}} |N(x)| - \sum_{x \neq s} 1 = 2m - (n-1)
$$

Let us examine now the \textbf{ideal time complexity of flooding}. Let $d(x, y)$ denote the \textbf{distance} (i.e., the length of the shortest path) between $x$ and $y$ in $G$. Clearly the message sent by the initiator has to reach every entity in the system, including the furthermost one from the initiator. So, if $x$ is the initiator, the \textbf{ideal time complexity} will be $r(x) = \max {d(x, y): y \in \mathcal{E}}$, which is called the eccentricity (or \textbf{radius}) of $x$. In other words, the total time depends on which entity is the initiator and thus cannot be known precisely beforehand. We can, however, determine exactly the ideal time complexity in the worst case. 

Since any entity could be the initiator, the ideal time complexity in the \textbf{worst case} will be $d(G) = \max {r(x): x \in \mathcal{E}}$, which is the \textbf{diameter} of $G$. In other words, the ideal time complexity will be at most the diameter of $G$:
$$\tim[\text{Flooding}] \leq d(G)$$